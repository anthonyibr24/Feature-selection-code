{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7y8UAx8K8s76/5hZk7OVM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anthonyibr24/Feature-selection-code/blob/Connectionist-Bench/Connectionist_Bench.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yVQTcNoOws9",
        "outputId": "5ac1e429-f5e7-4d80-c52a-03127d6c197c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2025.4.26)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "connectionist_bench_sonar_mines_vs_rocks = fetch_ucirepo(id=151)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = connectionist_bench_sonar_mines_vs_rocks.data.features\n",
        "y = connectionist_bench_sonar_mines_vs_rocks.data.targets\n",
        "\n",
        "# metadata\n",
        "print(connectionist_bench_sonar_mines_vs_rocks.metadata)\n",
        "\n",
        "# variable information\n",
        "print(connectionist_bench_sonar_mines_vs_rocks.variables)\n",
        "\n",
        "\n",
        "\n",
        "df=pd.concat([X,y],axis=1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6L-C7JbXNsj0",
        "outputId": "47624651-5011-4ca1-fa14-cf811007e066"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'uci_id': 151, 'name': 'Connectionist Bench (Sonar, Mines vs. Rocks)', 'repository_url': 'https://archive.ics.uci.edu/dataset/151/connectionist+bench+sonar+mines+vs+rocks', 'data_url': 'https://archive.ics.uci.edu/static/public/151/data.csv', 'abstract': 'The task is to train a network to discriminate between sonar signals bounced off a metal cylinder and those bounced off a roughly cylindrical rock.', 'area': 'Physics and Chemistry', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 208, 'num_features': 60, 'feature_types': ['Real'], 'demographics': [], 'target_col': ['class'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 1988, 'last_updated': None, 'dataset_doi': '10.24432/C5T01Q', 'creators': ['Terry Sejnowski', 'R. Gorman'], 'intro_paper': None, 'additional_info': {'summary': 'The file \"sonar.mines\" contains 111 patterns obtained by bouncing sonar signals off a metal cylinder at various angles and under various conditions.  The file \"sonar.rocks\" contains 97 patterns obtained from rocks under similar conditions.  The transmitted sonar signal is a frequency-modulated chirp, rising in frequency.  The data set contains signals obtained from a variety of different aspect angles, spanning 90 degrees for the cylinder and 180 degrees for the rock.\\r\\n\\r\\nEach pattern is a set of 60 numbers in the range 0.0 to 1.0.  Each number represents the energy within a particular frequency band, integrated over a certain period of time.  The integration aperture for higher frequencies occur later in time, since these frequencies are transmitted later during the chirp.\\r\\n\\r\\nThe label associated with each record contains the letter \"R\" if the object is a rock and \"M\" if it is a mine (metal cylinder).  The numbers in the labels are in increasing order of aspect angle, but they do not encode the angle directly.', 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': None, 'citation': None}}\n",
            "           name     role         type demographic description units  \\\n",
            "0    Attribute1  Feature   Continuous        None        None  None   \n",
            "1    Attribute2  Feature   Continuous        None        None  None   \n",
            "2    Attribute3  Feature   Continuous        None        None  None   \n",
            "3    Attribute4  Feature   Continuous        None        None  None   \n",
            "4    Attribute5  Feature   Continuous        None        None  None   \n",
            "..          ...      ...          ...         ...         ...   ...   \n",
            "56  Attribute57  Feature   Continuous        None        None  None   \n",
            "57  Attribute58  Feature   Continuous        None        None  None   \n",
            "58  Attribute59  Feature   Continuous        None        None  None   \n",
            "59  Attribute60  Feature   Continuous        None        None  None   \n",
            "60        class   Target  Categorical        None        None  None   \n",
            "\n",
            "   missing_values  \n",
            "0              no  \n",
            "1              no  \n",
            "2              no  \n",
            "3              no  \n",
            "4              no  \n",
            "..            ...  \n",
            "56             no  \n",
            "57             no  \n",
            "58             no  \n",
            "59             no  \n",
            "60             no  \n",
            "\n",
            "[61 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(200)\n",
        "print(df['class'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPnfeJ2dw1mD",
        "outputId": "9dbe46c7-8486-44c6-e3b6-1b4dbdc040c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class\n",
            "M    111\n",
            "R     97\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ecd-L69-x8h2",
        "outputId": "6a2fb321-e357-4932-8eb9-0e18af1025c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(208, 61)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import Bunch\n",
        "\n",
        "# Create a Bunch-like object for compatibility\n",
        "data_set = Bunch(\n",
        "    data=df.drop('class', axis=1).values,\n",
        "    target=df['class'].values,\n",
        "    feature_names=df.drop('class', axis=1).columns.tolist(),\n",
        ")\n",
        "\n",
        "\n",
        "#load dataset\n",
        "data=data_set\n",
        "df=pd.DataFrame(data.data,columns=data.feature_names)\n",
        "df['target']=data.target\n",
        "df.head()\n",
        "\n",
        "#scale mean=0 std=1\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler=StandardScaler()\n",
        "df=df.drop('target',axis=1)\n",
        "df[data.feature_names]=scaler.fit_transform(df[data.feature_names])\n",
        "\n",
        "df['target']=data.target\n",
        "df.describe().round(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "qciotgz5YMUa",
        "outputId": "f2bd442c-4766-405a-9caf-bf2bbee2c172"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       Attribute1  Attribute2  Attribute3  Attribute4  Attribute5  Attribute6  \\\n",
              "count     208.000     208.000     208.000     208.000     208.000     208.000   \n",
              "mean        0.000       0.000      -0.000       0.000      -0.000       0.000   \n",
              "std         1.002       1.002       1.002       1.002       1.002       1.002   \n",
              "min        -1.206      -1.151      -1.104      -1.036      -1.236      -1.600   \n",
              "25%        -0.689      -0.669      -0.649      -0.636      -0.670      -0.637   \n",
              "50%        -0.277      -0.232      -0.249      -0.212      -0.229      -0.211   \n",
              "75%         0.278       0.289       0.368       0.229       0.452       0.501   \n",
              "max         4.706       5.945       6.836       8.025       5.879       4.710   \n",
              "\n",
              "       Attribute7  Attribute8  Attribute9  Attribute10  ...  Attribute51  \\\n",
              "count     208.000     208.000     208.000      208.000  ...      208.000   \n",
              "mean        0.000       0.000      -0.000        0.000  ...        0.000   \n",
              "std         1.002       1.002       1.002        1.002  ...        1.002   \n",
              "min        -1.922      -1.522      -1.444       -1.469  ...       -1.341   \n",
              "25%        -0.663      -0.640      -0.686       -0.723  ...       -0.638   \n",
              "50%        -0.240      -0.267      -0.218       -0.193  ...       -0.181   \n",
              "75%         0.523       0.410       0.469        0.451  ...        0.397   \n",
              "max         4.075       3.816       4.274        3.746  ...        7.040   \n",
              "\n",
              "       Attribute52  Attribute53  Attribute54  Attribute55  Attribute56  \\\n",
              "count      208.000      208.000      208.000      208.000      208.000   \n",
              "mean         0.000        0.000       -0.000        0.000       -0.000   \n",
              "std          1.002        1.002        1.002        1.002        1.002   \n",
              "min         -1.313       -1.449       -1.365       -1.229       -1.367   \n",
              "25%         -0.639       -0.800       -0.764       -0.727       -0.668   \n",
              "50%         -0.210       -0.165       -0.225       -0.253       -0.240   \n",
              "75%          0.344        0.595        0.489        0.397        0.411   \n",
              "max          5.981        4.017        3.331        5.008        5.449   \n",
              "\n",
              "       Attribute57  Attribute58  Attribute59  Attribute60  \n",
              "count      208.000      208.000      208.000      208.000  \n",
              "mean         0.000       -0.000        0.000        0.000  \n",
              "std          1.002        1.002        1.002        1.002  \n",
              "min         -1.303       -1.185       -1.272       -1.177  \n",
              "25%         -0.714       -0.674       -0.692       -0.679  \n",
              "50%         -0.324       -0.333       -0.250       -0.241  \n",
              "75%          0.451        0.372        0.387        0.402  \n",
              "max          4.796        5.586        4.615        7.450  \n",
              "\n",
              "[8 rows x 60 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-884674a0-9ab6-4b27-8e35-798872b9954d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Attribute1</th>\n",
              "      <th>Attribute2</th>\n",
              "      <th>Attribute3</th>\n",
              "      <th>Attribute4</th>\n",
              "      <th>Attribute5</th>\n",
              "      <th>Attribute6</th>\n",
              "      <th>Attribute7</th>\n",
              "      <th>Attribute8</th>\n",
              "      <th>Attribute9</th>\n",
              "      <th>Attribute10</th>\n",
              "      <th>...</th>\n",
              "      <th>Attribute51</th>\n",
              "      <th>Attribute52</th>\n",
              "      <th>Attribute53</th>\n",
              "      <th>Attribute54</th>\n",
              "      <th>Attribute55</th>\n",
              "      <th>Attribute56</th>\n",
              "      <th>Attribute57</th>\n",
              "      <th>Attribute58</th>\n",
              "      <th>Attribute59</th>\n",
              "      <th>Attribute60</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>208.000</td>\n",
              "      <td>208.000</td>\n",
              "      <td>208.000</td>\n",
              "      <td>208.000</td>\n",
              "      <td>208.000</td>\n",
              "      <td>208.000</td>\n",
              "      <td>208.000</td>\n",
              "      <td>208.000</td>\n",
              "      <td>208.000</td>\n",
              "      <td>208.000</td>\n",
              "      <td>...</td>\n",
              "      <td>208.000</td>\n",
              "      <td>208.000</td>\n",
              "      <td>208.000</td>\n",
              "      <td>208.000</td>\n",
              "      <td>208.000</td>\n",
              "      <td>208.000</td>\n",
              "      <td>208.000</td>\n",
              "      <td>208.000</td>\n",
              "      <td>208.000</td>\n",
              "      <td>208.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>-0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.002</td>\n",
              "      <td>1.002</td>\n",
              "      <td>1.002</td>\n",
              "      <td>1.002</td>\n",
              "      <td>1.002</td>\n",
              "      <td>1.002</td>\n",
              "      <td>1.002</td>\n",
              "      <td>1.002</td>\n",
              "      <td>1.002</td>\n",
              "      <td>1.002</td>\n",
              "      <td>...</td>\n",
              "      <td>1.002</td>\n",
              "      <td>1.002</td>\n",
              "      <td>1.002</td>\n",
              "      <td>1.002</td>\n",
              "      <td>1.002</td>\n",
              "      <td>1.002</td>\n",
              "      <td>1.002</td>\n",
              "      <td>1.002</td>\n",
              "      <td>1.002</td>\n",
              "      <td>1.002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-1.206</td>\n",
              "      <td>-1.151</td>\n",
              "      <td>-1.104</td>\n",
              "      <td>-1.036</td>\n",
              "      <td>-1.236</td>\n",
              "      <td>-1.600</td>\n",
              "      <td>-1.922</td>\n",
              "      <td>-1.522</td>\n",
              "      <td>-1.444</td>\n",
              "      <td>-1.469</td>\n",
              "      <td>...</td>\n",
              "      <td>-1.341</td>\n",
              "      <td>-1.313</td>\n",
              "      <td>-1.449</td>\n",
              "      <td>-1.365</td>\n",
              "      <td>-1.229</td>\n",
              "      <td>-1.367</td>\n",
              "      <td>-1.303</td>\n",
              "      <td>-1.185</td>\n",
              "      <td>-1.272</td>\n",
              "      <td>-1.177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.689</td>\n",
              "      <td>-0.669</td>\n",
              "      <td>-0.649</td>\n",
              "      <td>-0.636</td>\n",
              "      <td>-0.670</td>\n",
              "      <td>-0.637</td>\n",
              "      <td>-0.663</td>\n",
              "      <td>-0.640</td>\n",
              "      <td>-0.686</td>\n",
              "      <td>-0.723</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.638</td>\n",
              "      <td>-0.639</td>\n",
              "      <td>-0.800</td>\n",
              "      <td>-0.764</td>\n",
              "      <td>-0.727</td>\n",
              "      <td>-0.668</td>\n",
              "      <td>-0.714</td>\n",
              "      <td>-0.674</td>\n",
              "      <td>-0.692</td>\n",
              "      <td>-0.679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-0.277</td>\n",
              "      <td>-0.232</td>\n",
              "      <td>-0.249</td>\n",
              "      <td>-0.212</td>\n",
              "      <td>-0.229</td>\n",
              "      <td>-0.211</td>\n",
              "      <td>-0.240</td>\n",
              "      <td>-0.267</td>\n",
              "      <td>-0.218</td>\n",
              "      <td>-0.193</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.181</td>\n",
              "      <td>-0.210</td>\n",
              "      <td>-0.165</td>\n",
              "      <td>-0.225</td>\n",
              "      <td>-0.253</td>\n",
              "      <td>-0.240</td>\n",
              "      <td>-0.324</td>\n",
              "      <td>-0.333</td>\n",
              "      <td>-0.250</td>\n",
              "      <td>-0.241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.278</td>\n",
              "      <td>0.289</td>\n",
              "      <td>0.368</td>\n",
              "      <td>0.229</td>\n",
              "      <td>0.452</td>\n",
              "      <td>0.501</td>\n",
              "      <td>0.523</td>\n",
              "      <td>0.410</td>\n",
              "      <td>0.469</td>\n",
              "      <td>0.451</td>\n",
              "      <td>...</td>\n",
              "      <td>0.397</td>\n",
              "      <td>0.344</td>\n",
              "      <td>0.595</td>\n",
              "      <td>0.489</td>\n",
              "      <td>0.397</td>\n",
              "      <td>0.411</td>\n",
              "      <td>0.451</td>\n",
              "      <td>0.372</td>\n",
              "      <td>0.387</td>\n",
              "      <td>0.402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>4.706</td>\n",
              "      <td>5.945</td>\n",
              "      <td>6.836</td>\n",
              "      <td>8.025</td>\n",
              "      <td>5.879</td>\n",
              "      <td>4.710</td>\n",
              "      <td>4.075</td>\n",
              "      <td>3.816</td>\n",
              "      <td>4.274</td>\n",
              "      <td>3.746</td>\n",
              "      <td>...</td>\n",
              "      <td>7.040</td>\n",
              "      <td>5.981</td>\n",
              "      <td>4.017</td>\n",
              "      <td>3.331</td>\n",
              "      <td>5.008</td>\n",
              "      <td>5.449</td>\n",
              "      <td>4.796</td>\n",
              "      <td>5.586</td>\n",
              "      <td>4.615</td>\n",
              "      <td>7.450</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 60 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-884674a0-9ab6-4b27-8e35-798872b9954d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-884674a0-9ab6-4b27-8e35-798872b9954d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-884674a0-9ab6-4b27-8e35-798872b9954d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5deee0bf-16d1-411d-8ead-e7b4a92ca953\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5deee0bf-16d1-411d-8ead-e7b4a92ca953')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5deee0bf-16d1-411d-8ead-e7b4a92ca953 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Full features"
      ],
      "metadata": {
        "id": "CVHacUKYgQM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Cross validation\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr=LogisticRegression(max_iter=2000)\n",
        "\n",
        "cv_results = cross_validate(\n",
        "    lr,\n",
        "    df.drop('target', axis=1),\n",
        "    df['target'],\n",
        "    cv=4,\n",
        "    scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro'],\n",
        "    return_train_score=False,\n",
        "\n",
        ")\n",
        "\n",
        "print(\"\\nAverage Metrics Across 4 Folds:\")\n",
        "print(f\"Accuracy:  {np.mean(cv_results['test_accuracy']):.4f} ± {np.std(cv_results['test_accuracy']):.4f}\")\n",
        "print(f\"Precision: {np.mean(cv_results['test_precision_macro']):.4f} ± {np.std(cv_results['test_precision_macro']):.4f}\")\n",
        "print(f\"Recall:    {np.mean(cv_results['test_recall_macro']):.4f} ± {np.std(cv_results['test_recall_macro']):.4f}\")\n",
        "print(f\"F1 Score:  {np.mean(cv_results['test_f1_macro']):.4f} ± {np.std(cv_results['test_f1_macro']):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raITrqC3cChs",
        "outputId": "39ba25a5-0be7-4ccc-d3fe-3fa9ec688e05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Average Metrics Across 4 Folds:\n",
            "Accuracy:  0.5817 ± 0.0516\n",
            "Precision: 0.6328 ± 0.0925\n",
            "Recall:    0.5824 ± 0.0465\n",
            "F1 Score:  0.5552 ± 0.0464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mutual Gain"
      ],
      "metadata": {
        "id": "MLUOwUKpq0P3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Mutual gain\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "#load dataset\n",
        "data=data_set\n",
        "df=pd.DataFrame(data.data,columns=data.feature_names)\n",
        "df['target']=data.target\n",
        "df.head()\n",
        "\n",
        "X=df.drop('target',axis=1)\n",
        "y=df['target']\n",
        "\n"
      ],
      "metadata": {
        "id": "e2XRC8bNmQ0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('selector', SelectKBest(mutual_info_classif, k=30)),\n",
        "    ('classifier', LogisticRegression())\n",
        "])\n",
        "pipeline.verbose=True\n",
        "\n",
        "#Cross-validate and calculate all metrics\n",
        "scores = cross_validate(\n",
        "    pipeline,\n",
        "    X, y,\n",
        "    cv=4,\n",
        "    scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
        ")\n",
        "\n",
        "print(\"\\nAverage Scores Across 4 Folds:\")\n",
        "for metric in ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']:\n",
        "    mean_score = scores[f'test_{metric}'].mean()\n",
        "    std_score = scores[f'test_{metric}'].std()\n",
        "    print(f\"{metric.capitalize()}: {mean_score:.4f} ± {std_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_U4IYId82Tx",
        "outputId": "e026dc26-c0ca-4b95-cb37-02c4a0849a8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Pipeline] ............ (step 1 of 3) Processing scaler, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.3s\n",
            "[Pipeline] ........ (step 3 of 3) Processing classifier, total=   0.0s\n",
            "[Pipeline] ............ (step 1 of 3) Processing scaler, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.3s\n",
            "[Pipeline] ........ (step 3 of 3) Processing classifier, total=   0.0s\n",
            "[Pipeline] ............ (step 1 of 3) Processing scaler, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.3s\n",
            "[Pipeline] ........ (step 3 of 3) Processing classifier, total=   0.0s\n",
            "[Pipeline] ............ (step 1 of 3) Processing scaler, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.3s\n",
            "[Pipeline] ........ (step 3 of 3) Processing classifier, total=   0.0s\n",
            "\n",
            "Average Scores Across 4 Folds:\n",
            "Accuracy: 0.5769 ± 0.0849\n",
            "Precision_macro: 0.6128 ± 0.1078\n",
            "Recall_macro: 0.5785 ± 0.0805\n",
            "F1_macro: 0.5578 ± 0.0804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ANOVA\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "\n",
        "#load dataset\n",
        "data=data_set\n",
        "df=pd.DataFrame(data.data,columns=data.feature_names)\n",
        "df['target']=data.target\n",
        "df.head()\n",
        "\n",
        "X=df.drop('target',axis=1)\n",
        "y=df['target']\n",
        "\n",
        "#Pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('selector', SelectKBest(score_func=f_classif, k=30)),\n",
        "    ('classifier', LogisticRegression())\n",
        "])\n",
        "pipeline.verbose=True\n",
        "\n",
        "#Cross-validate and calculate all metrics\n",
        "scores = cross_validate(\n",
        "    pipeline,\n",
        "    X, y,\n",
        "    cv=4,\n",
        "    scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
        ")\n",
        "\n",
        "print(\"\\nAverage Scores Across 4 Folds:\")\n",
        "for metric in ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']:\n",
        "    mean_score = scores[f'test_{metric}'].mean()\n",
        "    std_score = scores[f'test_{metric}'].std()\n",
        "    print(f\"{metric.capitalize()}: {mean_score:.4f} ± {std_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9Ga8INGttiS",
        "outputId": "333a2189-d222-4ee8-ff80-508233f6e4df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Pipeline] ............ (step 1 of 3) Processing scaler, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.0s\n",
            "[Pipeline] ........ (step 3 of 3) Processing classifier, total=   0.0s\n",
            "[Pipeline] ............ (step 1 of 3) Processing scaler, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.0s\n",
            "[Pipeline] ........ (step 3 of 3) Processing classifier, total=   0.3s\n",
            "[Pipeline] ............ (step 1 of 3) Processing scaler, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.0s\n",
            "[Pipeline] ........ (step 3 of 3) Processing classifier, total=   0.2s\n",
            "[Pipeline] ............ (step 1 of 3) Processing scaler, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.0s\n",
            "[Pipeline] ........ (step 3 of 3) Processing classifier, total=   0.2s\n",
            "\n",
            "Average Scores Across 4 Folds:\n",
            "Accuracy: 0.5817 ± 0.0250\n",
            "Precision_macro: 0.6317 ± 0.0761\n",
            "Recall_macro: 0.5834 ± 0.0266\n",
            "F1_macro: 0.5522 ± 0.0452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wrapper Methods"
      ],
      "metadata": {
        "id": "0d-qd7noBKW2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Forward"
      ],
      "metadata": {
        "id": "Epp4Psg4BkUT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#FORWARD\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import SequentialFeatureSelector\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "#load dataset\n",
        "data=data_set\n",
        "df=pd.DataFrame(data.data,columns=data.feature_names)\n",
        "df['target']=data.target\n",
        "df.head()\n",
        "\n",
        "X=df.drop('target',axis=1)\n",
        "y=df['target']\n",
        "\n",
        "knn=KNeighborsClassifier(5)\n",
        "\n"
      ],
      "metadata": {
        "id": "eUI0dbhABJH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('selector', SequentialFeatureSelector(knn, n_features_to_select=30, direction='forward', scoring='accuracy')),\n",
        "    ('classifier', LogisticRegression())\n",
        "])\n",
        "pipeline.verbose=True\n",
        "\n",
        "#Cross-validate and calculate all metrics\n",
        "scores = cross_validate(\n",
        "    pipeline,\n",
        "    X, y,\n",
        "    cv=4,\n",
        "    scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
        ")\n",
        "\n",
        "print(\"\\nAverage Scores Across 4 Folds:\")\n",
        "for metric in ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']:\n",
        "    mean_score = scores[f'test_{metric}'].mean()\n",
        "    std_score = scores[f'test_{metric}'].std()\n",
        "    print(f\"{metric.capitalize()}: {mean_score:.4f} ± {std_score:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9ph3zEYDiZ8",
        "outputId": "0c4d3679-1486-40b9-c58b-400976c87f08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Pipeline] ............ (step 1 of 3) Processing scaler, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing selector, total=  42.2s\n",
            "[Pipeline] ........ (step 3 of 3) Processing classifier, total=   0.0s\n",
            "[Pipeline] ............ (step 1 of 3) Processing scaler, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing selector, total=  41.0s\n",
            "[Pipeline] ........ (step 3 of 3) Processing classifier, total=   0.0s\n",
            "[Pipeline] ............ (step 1 of 3) Processing scaler, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing selector, total=  39.8s\n",
            "[Pipeline] ........ (step 3 of 3) Processing classifier, total=   0.0s\n",
            "[Pipeline] ............ (step 1 of 3) Processing scaler, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing selector, total=  39.4s\n",
            "[Pipeline] ........ (step 3 of 3) Processing classifier, total=   0.0s\n",
            "\n",
            "Average Scores Across 4 Folds:\n",
            "Accuracy: 0.6346 ± 0.0720\n",
            "Precision_macro: 0.6840 ± 0.0995\n",
            "Recall_macro: 0.6354 ± 0.0657\n",
            "F1_macro: 0.6161 ± 0.0661\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BACKWARD"
      ],
      "metadata": {
        "id": "tXSlIOUmIE_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#BACKWARD\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import SequentialFeatureSelector\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "#load dataset\n",
        "data=data_set\n",
        "df=pd.DataFrame(data.data,columns=data.feature_names)\n",
        "df['target']=data.target\n",
        "df.head()\n",
        "\n",
        "X=df.drop('target',axis=1)\n",
        "y=df['target']\n",
        "\n",
        "knn=KNeighborsClassifier(5)"
      ],
      "metadata": {
        "id": "LR5VBHU5IHsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('selector', SequentialFeatureSelector(knn, n_features_to_select=30, direction='backward', scoring='accuracy')),\n",
        "    ('classifier', LogisticRegression())\n",
        "])\n",
        "pipeline.verbose=True\n",
        "\n",
        "#Cross-validate and calculate all metrics\n",
        "scores = cross_validate(\n",
        "    pipeline,\n",
        "    X, y,\n",
        "    cv=4,\n",
        "    scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
        ")\n",
        "\n",
        "print(\"\\nAverage Scores Across 4 Folds:\")\n",
        "for metric in ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']:\n",
        "    mean_score = scores[f'test_{metric}'].mean()\n",
        "    std_score = scores[f'test_{metric}'].std()\n",
        "    print(f\"{metric.capitalize()}: {mean_score:.4f} ± {std_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQzx11AyILRV",
        "outputId": "61edfd3e-1403-4588-d4d6-6384bdb77b98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Pipeline] ............ (step 1 of 3) Processing scaler, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing selector, total=  28.3s\n",
            "[Pipeline] ........ (step 3 of 3) Processing classifier, total=   0.0s\n",
            "[Pipeline] ............ (step 1 of 3) Processing scaler, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing selector, total=  27.1s\n",
            "[Pipeline] ........ (step 3 of 3) Processing classifier, total=   0.0s\n",
            "[Pipeline] ............ (step 1 of 3) Processing scaler, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing selector, total=  26.9s\n",
            "[Pipeline] ........ (step 3 of 3) Processing classifier, total=   0.0s\n",
            "[Pipeline] ............ (step 1 of 3) Processing scaler, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing selector, total=  27.2s\n",
            "[Pipeline] ........ (step 3 of 3) Processing classifier, total=   0.2s\n",
            "\n",
            "Average Scores Across 4 Folds:\n",
            "Accuracy: 0.5913 ± 0.0698\n",
            "Precision_macro: 0.6349 ± 0.1083\n",
            "Recall_macro: 0.5927 ± 0.0683\n",
            "F1_macro: 0.5723 ± 0.0614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RFE"
      ],
      "metadata": {
        "id": "Ok-58U7ULAc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#RFE\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#load dataset\n",
        "data=data_set\n",
        "df=pd.DataFrame(data.data,columns=data.feature_names)\n",
        "df['target']=data.target\n",
        "df.head()\n",
        "\n",
        "X=df.drop('target',axis=1)\n",
        "y=df['target']\n",
        "\n"
      ],
      "metadata": {
        "id": "R4lBZTL2KCzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('selector', RFE(estimator=SVC(kernel='linear'), n_features_to_select=30)),\n",
        "    ('classifier', LogisticRegression())\n",
        "])\n",
        "pipeline.verbose=True\n",
        "\n",
        "#Cross-validate and calculate all metrics\n",
        "scores = cross_validate(\n",
        "    pipeline,\n",
        "    X, y,\n",
        "    cv=4,\n",
        "    scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
        ")\n",
        "\n",
        "print(\"\\nAverage Scores Across 4 Folds:\")\n",
        "for metric in ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']:\n",
        "    mean_score = scores[f'test_{metric}'].mean()\n",
        "    std_score = scores[f'test_{metric}'].std()\n",
        "    print(f\"{metric.capitalize()}: {mean_score:.4f} ± {std_score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fUriSGLbMDFT",
        "outputId": "ae468d46-f7e2-49c4-990e-10164495d2e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Pipeline] ............ (step 1 of 3) Processing scaler, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.2s\n",
            "[Pipeline] ........ (step 3 of 3) Processing classifier, total=   0.0s\n",
            "[Pipeline] ............ (step 1 of 3) Processing scaler, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.4s\n",
            "[Pipeline] ........ (step 3 of 3) Processing classifier, total=   0.1s\n",
            "[Pipeline] ............ (step 1 of 3) Processing scaler, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.3s\n",
            "[Pipeline] ........ (step 3 of 3) Processing classifier, total=   0.2s\n",
            "[Pipeline] ............ (step 1 of 3) Processing scaler, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.4s\n",
            "[Pipeline] ........ (step 3 of 3) Processing classifier, total=   0.2s\n",
            "\n",
            "Average Scores Across 4 Folds:\n",
            "Accuracy: 0.5625 ± 0.0643\n",
            "Precision_macro: 0.5991 ± 0.0844\n",
            "Recall_macro: 0.5631 ± 0.0571\n",
            "F1_macro: 0.5344 ± 0.0584\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embeded Methods"
      ],
      "metadata": {
        "id": "WIyoDunvOQFJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Random Forest"
      ],
      "metadata": {
        "id": "vc8DScVOPovL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#RF\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "\n",
        "#load dataset\n",
        "data=data_set\n",
        "df=pd.DataFrame(data.data,columns=data.feature_names)\n",
        "df['target']=data.target\n",
        "df.head()\n",
        "\n",
        "X=df.drop('target',axis=1)\n",
        "y=df['target']\n"
      ],
      "metadata": {
        "id": "-fu9WLj-OTUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('selector', SelectFromModel(RandomForestClassifier(random_state=42), max_features=30)),\n",
        "    ('classifier', LogisticRegression())\n",
        "])\n",
        "pipeline.verbose=True\n",
        "\n",
        "#Cross-validate and calculate all metrics\n",
        "scores = cross_validate(\n",
        "    pipeline,\n",
        "    X, y,\n",
        "    cv=4,\n",
        "    scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
        ")\n",
        "\n",
        "print(\"\\nAverage Scores Across 4 Folds:\")\n",
        "for metric in ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']:\n",
        "    mean_score = scores[f'test_{metric}'].mean()\n",
        "    std_score = scores[f'test_{metric}'].std()\n",
        "    print(f\"{metric.capitalize()}: {mean_score:.4f} ± {std_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwmtSwLbPtuE",
        "outputId": "c8c8153d-48fd-435f-cd7e-0f21d1238a84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Pipeline] ............ (step 1 of 3) Processing scaler, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.7s\n",
            "[Pipeline] ........ (step 3 of 3) Processing classifier, total=   0.0s\n",
            "[Pipeline] ............ (step 1 of 3) Processing scaler, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.8s\n",
            "[Pipeline] ........ (step 3 of 3) Processing classifier, total=   0.3s\n",
            "[Pipeline] ............ (step 1 of 3) Processing scaler, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.8s\n",
            "[Pipeline] ........ (step 3 of 3) Processing classifier, total=   0.0s\n",
            "[Pipeline] ............ (step 1 of 3) Processing scaler, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.4s\n",
            "[Pipeline] ........ (step 3 of 3) Processing classifier, total=   0.0s\n",
            "\n",
            "Average Scores Across 4 Folds:\n",
            "Accuracy: 0.5721 ± 0.0614\n",
            "Precision_macro: 0.6178 ± 0.1016\n",
            "Recall_macro: 0.5789 ± 0.0602\n",
            "F1_macro: 0.5547 ± 0.0648\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic using L1 penalty"
      ],
      "metadata": {
        "id": "4G1Owl6yS5kA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#LR L1 penalty\n",
        "from sklearn.datasets import load_wine\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "\n",
        "\n",
        "#load dataset\n",
        "data=data_set\n",
        "df=pd.DataFrame(data.data,columns=data.feature_names)\n",
        "df['target']=data.target\n",
        "df.head()\n",
        "\n",
        "X=df.drop('target',axis=1)\n",
        "y=df['target']\n"
      ],
      "metadata": {
        "id": "LNEse-zUTMQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pipeline\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('selector', SelectFromModel(LogisticRegression(penalty='l1',solver='saga',C=0.1,max_iter=3000,random_state=42),max_features=30)),\n",
        "    ('classifier', LogisticRegression())\n",
        "])\n",
        "pipeline.verbose=True\n",
        "\n",
        "#Cross-validate and calculate all metrics\n",
        "scores = cross_validate(\n",
        "    pipeline,\n",
        "    X, y,\n",
        "    cv=4,\n",
        "    scoring=['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
        ")\n",
        "\n",
        "print(\"\\nAverage Scores Across 4 Folds:\")\n",
        "for metric in ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']:\n",
        "    mean_score = scores[f'test_{metric}'].mean()\n",
        "    std_score = scores[f'test_{metric}'].std()\n",
        "    print(f\"{metric.capitalize()}: {mean_score:.4f} ± {std_score:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgHtiXkHTQIO",
        "outputId": "5262c65d-5bd9-4838-cca3-686d63220a4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Pipeline] ............ (step 1 of 3) Processing scaler, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.1s\n",
            "[Pipeline] ........ (step 3 of 3) Processing classifier, total=   0.0s\n",
            "[Pipeline] ............ (step 1 of 3) Processing scaler, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.2s\n",
            "[Pipeline] ........ (step 3 of 3) Processing classifier, total=   0.0s\n",
            "[Pipeline] ............ (step 1 of 3) Processing scaler, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.1s\n",
            "[Pipeline] ........ (step 3 of 3) Processing classifier, total=   0.0s\n",
            "[Pipeline] ............ (step 1 of 3) Processing scaler, total=   0.0s\n",
            "[Pipeline] .......... (step 2 of 3) Processing selector, total=   0.1s\n",
            "[Pipeline] ........ (step 3 of 3) Processing classifier, total=   0.0s\n",
            "\n",
            "Average Scores Across 4 Folds:\n",
            "Accuracy: 0.5769 ± 0.0652\n",
            "Precision_macro: 0.6321 ± 0.0908\n",
            "Recall_macro: 0.5802 ± 0.0563\n",
            "F1_macro: 0.5459 ± 0.0786\n"
          ]
        }
      ]
    }
  ]
}